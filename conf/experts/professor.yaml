# Professor Expert Configuration
# Llama-3.2-3B for reasoning tasks

name: professor
model: llama3.2:3b
provider: ollama
endpoint: http://localhost:11434
max_tokens: 2048
temperature: 0.7

